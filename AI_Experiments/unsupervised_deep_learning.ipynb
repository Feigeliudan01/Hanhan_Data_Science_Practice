{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import keras\n",
    "import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "from time import time\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Input\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "from scipy.misc import imread\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score\n",
    "\n",
    "# run the code under DEC-keras\n",
    "## git clone https://github.com/XifengGuo/DEC-keras\n",
    "## cd DEC-keras\n",
    "\n",
    "# download the data from: https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 410  # I miss him, miss him so much\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('.')\n",
    "data_dir = os.path.join(root_dir, 'data', 'minist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I moved the downloaded data into /minist\n",
    "train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niR9CiR9C/QC5SOw9zbV0vwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122f2e5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# randomly chose the digit to print out\n",
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir, 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the images into numpy array\n",
    "def image2array(image_folder_path, filename_lst):\n",
    "    temp = []\n",
    "    for img_name in filename_lst.filename:\n",
    "        image_path = os.path.join(image_folder_path, img_name)\n",
    "        img = imread(image_path, flatten=True)\n",
    "        img = img.astype('float32')\n",
    "        temp.append(img)\n",
    "\n",
    "    data_x = np.stack(temp)\n",
    "\n",
    "    data_x /= 255.0\n",
    "    data_x = data_x.reshape(-1, 784).astype('float32')\n",
    "    \n",
    "    return data_x\n",
    "\n",
    "train_x = image2array(os.path.join(data_dir, 'train'), train)\n",
    "test_x = image2array(os.path.join(data_dir, 'test'), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 9, 4, 9, 3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.label.values\n",
    "train_y[4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide the training data into training and validation\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=20, n_jobs=-1, precompute_distances='auto',\n",
       "    random_state=410, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1 - Just use kmeans\n",
    "km = KMeans(n_jobs=-1, n_clusters=10, n_init=20, random_state=410)  # n_init is the number of times to run\n",
    "km.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49702986222381257"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = km.predict(val_x)\n",
    "normalized_mutual_info_score(val_y, pred)  # using normalized mutual info (NMI) for the evaluation, higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2000)              22000     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 784)               392784    \n",
      "=================================================================\n",
      "Total params: 3,330,794\n",
      "Trainable params: 3,330,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 2 - autoencode to reduce dimension and extract useful info, then pass to kmeans\n",
    "## input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "## \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(500, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(2000, activation='relu')(encoded)\n",
    "encoded = Dense(10, activation='sigmoid')(encoded)\n",
    "\n",
    "## \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(2000, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(784)(decoded)\n",
    "\n",
    "## this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/30\n",
      "34300/34300 [==============================] - 24s - loss: 0.0341 - val_loss: 0.0273\n",
      "Epoch 2/30\n",
      "34300/34300 [==============================] - 25s - loss: 0.0255 - val_loss: 0.0244\n",
      "Epoch 3/30\n",
      "34300/34300 [==============================] - 29s - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 4/30\n",
      "34300/34300 [==============================] - 30s - loss: 0.0229 - val_loss: 0.0231\n",
      "Epoch 5/30\n",
      "34300/34300 [==============================] - 24s - loss: 0.0226 - val_loss: 0.0228\n",
      "Epoch 6/30\n",
      "34300/34300 [==============================] - 26s - loss: 0.0224 - val_loss: 0.0226\n",
      "Epoch 7/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0221 - val_loss: 0.0224\n",
      "Epoch 8/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0219 - val_loss: 0.0222\n",
      "Epoch 9/30\n",
      "34300/34300 [==============================] - 25s - loss: 0.0217 - val_loss: 0.0220\n",
      "Epoch 10/30\n",
      "34300/34300 [==============================] - 27s - loss: 0.0214 - val_loss: 0.0217\n",
      "Epoch 11/30\n",
      "34300/34300 [==============================] - 24s - loss: 0.0212 - val_loss: 0.0215\n",
      "Epoch 12/30\n",
      "34300/34300 [==============================] - 24s - loss: 0.0210 - val_loss: 0.0214\n",
      "Epoch 13/30\n",
      "34300/34300 [==============================] - 24s - loss: 0.0208 - val_loss: 0.0212\n",
      "Epoch 14/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0207 - val_loss: 0.0213\n",
      "Epoch 15/30\n",
      "34300/34300 [==============================] - 21s - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 16/30\n",
      "34300/34300 [==============================] - 23s - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 17/30\n",
      "34300/34300 [==============================] - 25s - loss: 0.0201 - val_loss: 0.0205\n",
      "Epoch 18/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0201 - val_loss: 0.0205\n",
      "Epoch 19/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 20/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0196 - val_loss: 0.0201\n",
      "Epoch 21/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0196 - val_loss: 0.0202\n",
      "Epoch 22/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0194 - val_loss: 0.0199\n",
      "Epoch 23/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0195 - val_loss: 0.0199\n",
      "Epoch 24/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0191 - val_loss: 0.0197\n",
      "Epoch 25/30\n",
      "34300/34300 [==============================] - 22s - loss: 0.0189 - val_loss: 0.0195\n",
      "Epoch 26/30\n",
      "34300/34300 [==============================] - 21s - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 27/30\n",
      "34300/34300 [==============================] - 24s - loss: 0.0187 - val_loss: 0.0194\n",
      "Epoch 28/30\n",
      "34300/34300 [==============================] - 24s - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 29/30\n",
      "34300/34300 [==============================] - 23s - loss: 0.0187 - val_loss: 0.0195\n",
      "Epoch 30/30\n",
      "34300/34300 [==============================] - 26s - loss: 0.0185 - val_loss: 0.0192\n"
     ]
    }
   ],
   "source": [
    "# train the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "train_history = autoencoder.fit(train_x, train_x, epochs=30, batch_size=2048, validation_data=(val_x, val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  this model maps an input to its encoded representation\n",
    "### this part takes a while\n",
    "encoder = Model(input_img, encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_auto_train = encoder.predict(train_x)\n",
    "pred_auto = encoder.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km.fit(pred_auto_train)\n",
    "pred = km.predict(pred_auto)\n",
    "\n",
    "normalized_mutual_info_score(val_y, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
