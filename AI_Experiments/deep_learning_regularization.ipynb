{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Regularization\n",
    "\n",
    "üòìBe well prepared that when the code worked for me, may not work for you any more. It took me so much time tonight to debug, upgrade/install packages, change deprecated functions or just ignore warnings.... All because the frequent changes in these open source packages. So, when it's your turn to try the code, who know whether it still works...\n",
    "\n",
    "üíùHowever, when you are seeing my code, you are lucky! At least I took the note on those things need to care about, including the solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pylab\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NOTE\n",
    "\n",
    "You may got an error saying cannot import module \"weakref\". This problem was not exist before but just appeared...\n",
    "Here's my solution:\n",
    "1. Find your tensorflow path by typing `pip show tensorflow`\n",
    "2. Find tensorflow/python/util/tf_should_use.py, open it\n",
    "3. Change `from backports import weakref` to `import weakref`\n",
    "4. Then comment the line that contains `finalize()` function, this is for garbage collection, but finalize function does not exist in weakref in my case.... üòì\n",
    "5. Restart your ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 10\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('digit_recognition/train.csv')\n",
    "test = pd.read_csv('digit_recognition/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDxYAB7XdTLH6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1295b7a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "training_image_path = 'digit_recognition/Images/train/' + img_name\n",
    "\n",
    "training_img = imread(training_image_path, as_gray=True)\n",
    "\n",
    "pylab.imshow(training_img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   6.,  67., 239., 177.,  34.,  77., 143., 143., 143., 137.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,  73., 252., 252., 253., 252., 252., 252., 252., 252., 241.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_img[7:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all images as numpy arrays, to make data manipulation easier\n",
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    training_image_path = 'digit_recognition/Images/train/' + img_name\n",
    "    training_img = imread(training_image_path, as_gray=True)\n",
    "    img = training_img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "train_x /= 255.0\n",
    "train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    testing_image_path = 'digit_recognition/Images/test/' + img_name\n",
    "    testing_img = imread(testing_image_path, as_gray=True)\n",
    "    img = testing_img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and validation sets, 7:3\n",
    "\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34300    3\n",
       "34301    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.iloc[split_size:split_size+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define variables\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "Keras updated to 2.0\n",
    "Without updating keras, the way you used `Dense()` function may keep giving warnings\n",
    "\n",
    "* Here's Keras 2.0 documentation: https://keras.io/\n",
    "* To update keras, type `sudo pip install --upgrade keras==2.1.3`. Has to be keras 2.1.3, if it's higher, softmax may get an error below.... (this is why I hate deep learning when you have to use open source!)\n",
    "* Holy s**t, even after the updating, you will get many warnings again, just ignore them.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Method 1 - Without Regularization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/5\n",
      "34300/34300 [==============================] - 20s 578us/step - loss: 0.3041 - acc: 0.9056 - val_loss: 0.1740 - val_acc: 0.9493\n",
      "Epoch 2/5\n",
      "34300/34300 [==============================] - 19s 542us/step - loss: 0.1331 - acc: 0.9609 - val_loss: 0.1212 - val_acc: 0.9672\n",
      "Epoch 3/5\n",
      "34300/34300 [==============================] - 19s 540us/step - loss: 0.0870 - acc: 0.9742 - val_loss: 0.1300 - val_acc: 0.9655\n",
      "Epoch 4/5\n",
      "34300/34300 [==============================] - 16s 479us/step - loss: 0.0703 - acc: 0.9800 - val_loss: 0.1174 - val_acc: 0.9688\n",
      "Epoch 5/5\n",
      "34300/34300 [==============================] - 18s 512us/step - loss: 0.0540 - acc: 0.9842 - val_loss: 0.1301 - val_acc: 0.9697\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f5507d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model evaluation\n",
    "\n",
    "pred = model.predict_classes(test_x)\n",
    "\n",
    "img_name = rng.choice(test.filename)\n",
    "testing_image_path = 'digit_recognition/Images/test/' + img_name\n",
    "testing_img = imread(testing_image_path, as_gray=True)\n",
    "\n",
    "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
    "\n",
    "print \"Prediction is: \", pred[test_index]\n",
    "\n",
    "pylab.imshow(testing_img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method 2 - With L2 regularizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_virtualenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
