{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Regularization\n",
    "\n",
    "üòìBe well prepared that when the code worked for me, may not work for you any more. It took me so much time tonight to debug, upgrade/install packages, change deprecated functions or just ignore warnings.... All because of the frequent changes in these open source packages. So, when it's your turn to try the code, who knows whether it still works...\n",
    "\n",
    "üíùHowever, when you are seeing my code, you are lucky! At least I took the note on those things need to care about, including the solutions.\n",
    "\n",
    "‚ù£Ô∏èAlso note, the model evaluation here I didn't evauate all the testing data, because of the labeling time for all those testing image can be huge and I'm really busy. <b>However</b>, you can pay attention to those val_acc and val_loss, lower the better\n",
    "\n",
    "Reference: https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29\n",
    "\n",
    "<b>Get data from here</b>: https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imageio import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pylab\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NOTE\n",
    "\n",
    "You may got an error saying cannot import module \"weakref\". This problem was not exist before but just appeared...\n",
    "Here's my solution:\n",
    "1. Find your tensorflow path by typing `pip show tensorflow`\n",
    "2. Find tensorflow/python/util/tf_should_use.py, open it\n",
    "3. Change `from backports import weakref` to `import weakref`\n",
    "4. Then comment the line that contains `finalize()` function, this is for garbage collection, but finalize function does not exist in weakref in my case.... üòì\n",
    "5. Restart your ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 10\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('digit_recognition/train.csv')\n",
    "test = pd.read_csv('digit_recognition/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10740e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "training_image_path = 'digit_recognition/Images/train/' + img_name\n",
    "\n",
    "training_img = imread(training_image_path, as_gray=True)\n",
    "\n",
    "pylab.imshow(training_img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  20., 147., 147., 142.,\n",
       "         39.,  39.,   4.,   0.,   0.,  46.,  50.,   0.,   0.,   0.,  77.,\n",
       "        254.,  76.,   0.,   0.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_img[7:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store all images as numpy arrays, to make data manipulation easier\n",
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    training_image_path = 'digit_recognition/Images/train/' + img_name\n",
    "    training_img = imread(training_image_path, as_gray=True)\n",
    "    img = training_img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "train_x /= 255.0\n",
    "train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    testing_image_path = 'digit_recognition/Images/test/' + img_name\n",
    "    testing_img = imread(testing_image_path, as_gray=True)\n",
    "    img = testing_img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and validation sets, 7:3\n",
    "\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34300    3\n",
       "34301    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.iloc[split_size:split_size+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define variables\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "Keras updated to 2.0\n",
    "Without updating keras, the way you used `Dense()` function may keep giving warnings\n",
    "\n",
    "* Here's Keras 2.0 documentation: https://keras.io/\n",
    "* To update keras, type `sudo pip install --upgrade keras==2.1.3`. Has to be keras 2.1.3, if it's higher, softmax may get an error below.... (this is why I hate deep learning when you have to use open source!)\n",
    "* Holy s**t, even after the updating, you will get many warnings again, just ignore them.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method 1 - Without Regularization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'))\n",
    "model.add(Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/10\n",
      "34300/34300 [==============================] - 20s 595us/step - loss: 0.3075 - acc: 0.9044 - val_loss: 0.1898 - val_acc: 0.9454\n",
      "Epoch 2/10\n",
      "34300/34300 [==============================] - 19s 562us/step - loss: 0.1248 - acc: 0.9633 - val_loss: 0.1333 - val_acc: 0.9607\n",
      "Epoch 3/10\n",
      "34300/34300 [==============================] - 20s 572us/step - loss: 0.0876 - acc: 0.9734 - val_loss: 0.1119 - val_acc: 0.9705\n",
      "Epoch 4/10\n",
      "34300/34300 [==============================] - 20s 586us/step - loss: 0.0627 - acc: 0.9806 - val_loss: 0.1204 - val_acc: 0.9681\n",
      "Epoch 5/10\n",
      "34300/34300 [==============================] - 20s 586us/step - loss: 0.0545 - acc: 0.9838 - val_loss: 0.1187 - val_acc: 0.9711\n",
      "Epoch 6/10\n",
      "34300/34300 [==============================] - 20s 588us/step - loss: 0.0470 - acc: 0.9858 - val_loss: 0.1165 - val_acc: 0.9731\n",
      "Epoch 7/10\n",
      "34300/34300 [==============================] - 20s 593us/step - loss: 0.0437 - acc: 0.9873 - val_loss: 0.1081 - val_acc: 0.9744\n",
      "Epoch 8/10\n",
      "34300/34300 [==============================] - 20s 583us/step - loss: 0.0345 - acc: 0.9899 - val_loss: 0.1444 - val_acc: 0.9670\n",
      "Epoch 9/10\n",
      "34300/34300 [==============================] - 20s 587us/step - loss: 0.0342 - acc: 0.9901 - val_loss: 0.1263 - val_acc: 0.9726\n",
      "Epoch 10/10\n",
      "34300/34300 [==============================] - 20s 592us/step - loss: 0.0273 - acc: 0.9928 - val_loss: 0.1238 - val_acc: 0.9718\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f5507d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# one sample evaluation\n",
    "\n",
    "pred = model.predict_classes(test_x)\n",
    "\n",
    "img_name = rng.choice(test.filename)\n",
    "testing_image_path = 'digit_recognition/Images/test/' + img_name\n",
    "testing_img = imread(testing_image_path, as_gray=True)\n",
    "\n",
    "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
    "\n",
    "print \"Prediction is: \", pred[test_index]\n",
    "\n",
    "pylab.imshow(testing_img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method 2 - With L2 regularizer\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),  # lambda  = 0.0001\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l2(0.0001)),\n",
    " Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/10\n",
      "34300/34300 [==============================] - 44s 1ms/step - loss: 0.4895 - acc: 0.9100 - val_loss: 0.3137 - val_acc: 0.9559\n",
      "Epoch 2/10\n",
      "34300/34300 [==============================] - 72s 2ms/step - loss: 0.2882 - acc: 0.9628 - val_loss: 0.2913 - val_acc: 0.9612\n",
      "Epoch 3/10\n",
      "34300/34300 [==============================] - 41s 1ms/step - loss: 0.2332 - acc: 0.9743 - val_loss: 0.2642 - val_acc: 0.9664\n",
      "Epoch 4/10\n",
      "34300/34300 [==============================] - 43s 1ms/step - loss: 0.2073 - acc: 0.9789 - val_loss: 0.2475 - val_acc: 0.9665\n",
      "Epoch 5/10\n",
      "34300/34300 [==============================] - 31s 918us/step - loss: 0.1816 - acc: 0.9837 - val_loss: 0.2258 - val_acc: 0.9705\n",
      "Epoch 6/10\n",
      "34300/34300 [==============================] - 27s 802us/step - loss: 0.1630 - acc: 0.9857 - val_loss: 0.2180 - val_acc: 0.9710\n",
      "Epoch 7/10\n",
      "34300/34300 [==============================] - 29s 855us/step - loss: 0.1530 - acc: 0.9862 - val_loss: 0.2126 - val_acc: 0.9726\n",
      "Epoch 8/10\n",
      "34300/34300 [==============================] - 35s 1ms/step - loss: 0.1393 - acc: 0.9882 - val_loss: 0.2115 - val_acc: 0.9712\n",
      "Epoch 9/10\n",
      "34300/34300 [==============================] - 33s 958us/step - loss: 0.1339 - acc: 0.9883 - val_loss: 0.2196 - val_acc: 0.9661\n",
      "Epoch 10/10\n",
      "34300/34300 [==============================] - 33s 965us/step - loss: 0.1197 - acc: 0.9911 - val_loss: 0.2042 - val_acc: 0.9701\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method 3 - L1 Regularizer\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu',\n",
    " kernel_regularizer=regularizers.l1(0.0001)),\n",
    " Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/10\n",
      "34300/34300 [==============================] - 27s 799us/step - loss: 2.8674 - acc: 0.9038 - val_loss: 1.7857 - val_acc: 0.9503\n",
      "Epoch 2/10\n",
      "34300/34300 [==============================] - 28s 804us/step - loss: 1.3601 - acc: 0.9543 - val_loss: 1.0440 - val_acc: 0.9523\n",
      "Epoch 3/10\n",
      "34300/34300 [==============================] - 28s 806us/step - loss: 0.8408 - acc: 0.9619 - val_loss: 0.7174 - val_acc: 0.9544\n",
      "Epoch 4/10\n",
      "34300/34300 [==============================] - 28s 805us/step - loss: 0.5903 - acc: 0.9688 - val_loss: 0.5198 - val_acc: 0.9683\n",
      "Epoch 5/10\n",
      "34300/34300 [==============================] - 29s 843us/step - loss: 0.4596 - acc: 0.9717 - val_loss: 0.4388 - val_acc: 0.9662\n",
      "Epoch 6/10\n",
      "34300/34300 [==============================] - 28s 805us/step - loss: 0.3848 - acc: 0.9737 - val_loss: 0.4031 - val_acc: 0.9627\n",
      "Epoch 7/10\n",
      "34300/34300 [==============================] - 30s 883us/step - loss: 0.3303 - acc: 0.9776 - val_loss: 0.3565 - val_acc: 0.9633\n",
      "Epoch 8/10\n",
      "34300/34300 [==============================] - 28s 813us/step - loss: 0.2965 - acc: 0.9786 - val_loss: 0.3257 - val_acc: 0.9686\n",
      "Epoch 9/10\n",
      "34300/34300 [==============================] - 30s 867us/step - loss: 0.2711 - acc: 0.9808 - val_loss: 0.2952 - val_acc: 0.9712\n",
      "Epoch 10/10\n",
      "34300/34300 [==============================] - 36s 1ms/step - loss: 0.2525 - acc: 0.9815 - val_loss: 0.2895 - val_acc: 0.9699\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method 4 - Dropout\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.25),  # the drop probability is 0.25\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/10\n",
      "34300/34300 [==============================] - 27s 787us/step - loss: 0.4204 - acc: 0.8669 - val_loss: 0.1686 - val_acc: 0.9507\n",
      "Epoch 2/10\n",
      "34300/34300 [==============================] - 26s 771us/step - loss: 0.1715 - acc: 0.9497 - val_loss: 0.1343 - val_acc: 0.9601\n",
      "Epoch 3/10\n",
      "34300/34300 [==============================] - 26s 763us/step - loss: 0.1356 - acc: 0.9606 - val_loss: 0.1173 - val_acc: 0.9668\n",
      "Epoch 4/10\n",
      "34300/34300 [==============================] - 27s 776us/step - loss: 0.1038 - acc: 0.9692 - val_loss: 0.1060 - val_acc: 0.9705\n",
      "Epoch 5/10\n",
      "34300/34300 [==============================] - 30s 881us/step - loss: 0.0897 - acc: 0.9738 - val_loss: 0.1223 - val_acc: 0.9676\n",
      "Epoch 6/10\n",
      "34300/34300 [==============================] - 29s 841us/step - loss: 0.0785 - acc: 0.9774 - val_loss: 0.1158 - val_acc: 0.9703\n",
      "Epoch 7/10\n",
      "34300/34300 [==============================] - 27s 793us/step - loss: 0.0673 - acc: 0.9806 - val_loss: 0.1186 - val_acc: 0.9717\n",
      "Epoch 8/10\n",
      "34300/34300 [==============================] - 27s 790us/step - loss: 0.0645 - acc: 0.9809 - val_loss: 0.1080 - val_acc: 0.9731\n",
      "Epoch 9/10\n",
      "34300/34300 [==============================] - 26s 758us/step - loss: 0.0586 - acc: 0.9827 - val_loss: 0.1012 - val_acc: 0.9741\n",
      "Epoch 10/10\n",
      "34300/34300 [==============================] - 27s 778us/step - loss: 0.0560 - acc: 0.9836 - val_loss: 0.1046 - val_acc: 0.9748\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 5 - early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.core import Dropout\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.25),  # the drop probability is 0.25\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/10\n",
      "34300/34300 [==============================] - 20s 582us/step - loss: 0.4231 - acc: 0.8689 - val_loss: 0.2190 - val_acc: 0.9376\n",
      "Epoch 2/10\n",
      "34300/34300 [==============================] - 18s 516us/step - loss: 0.1737 - acc: 0.9499 - val_loss: 0.1651 - val_acc: 0.9529\n",
      "Epoch 3/10\n",
      "34300/34300 [==============================] - 15s 450us/step - loss: 0.1371 - acc: 0.9607 - val_loss: 0.1119 - val_acc: 0.9675\n",
      "Epoch 4/10\n",
      "34300/34300 [==============================] - 16s 469us/step - loss: 0.1083 - acc: 0.9681 - val_loss: 0.1044 - val_acc: 0.9703\n",
      "Epoch 5/10\n",
      "34300/34300 [==============================] - 18s 529us/step - loss: 0.0880 - acc: 0.9736 - val_loss: 0.1034 - val_acc: 0.9720\n",
      "Epoch 6/10\n",
      "34300/34300 [==============================] - 16s 455us/step - loss: 0.0793 - acc: 0.9769 - val_loss: 0.1121 - val_acc: 0.9707\n",
      "Epoch 7/10\n",
      "34300/34300 [==============================] - 15s 446us/step - loss: 0.0708 - acc: 0.9793 - val_loss: 0.1167 - val_acc: 0.9713\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y),\n",
    "                            callbacks = [EarlyStopping(monitor='val_acc', patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 6 - Data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zca_whitening=True)  \n",
    "# zca_whitening as the argument, will highlight the outline of each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('digit_recognition/train.csv')\n",
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    training_image_path = 'digit_recognition/Images/train/' + img_name\n",
    "    training_img = imread(training_image_path, as_gray=True)\n",
    "    img = training_img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "# The difference with above starts from here:\n",
    "train_x = train_x.reshape(train_x.shape[0], 1, 28, 28)\n",
    "train_x = train_x.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit parameters from data\n",
    "## fit the training data in order to augment\n",
    "datagen.fit(train_x)  # This will often cause the kernel to die on my machine\n",
    "\n",
    "# data spliting\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]\n",
    "\n",
    "# train the model with drop out\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.25),  # the drop probability is 0.25\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.25),\n",
    " Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    " ])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "1. Comparing the val_loss and vall_acc between each regularizer and the first method, we can see dropout works best and it is thr only one that has lower val_loss and higher val_acc. \n",
    "2. In the experiments here, after we applied early stopping on dropout it didn't give better results, maybe it needs more `patience`, because if we observe each epoch, the val_loss is not simply dropping along the way, it could increase in the middle and then drop again. This is why we need to be careful towards the number of epoch/patience\n",
    "3. L1, L2 tend to give higher val_loss, especially L1\n",
    "4. In my machine, with limited memory now, data augmentation failed, it will simply kill the kernel all the time. No wonder dropout is the most frequently used regularizer....."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_virtualenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
