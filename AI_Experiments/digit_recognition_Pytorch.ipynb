{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Pytorch with Digit Recognition\n",
    "\n",
    "* Reference: https://www.analyticsvidhya.com/blog/2018/02/pytorch-tutorial/\n",
    "  * <b>Some functions are wrong or out of dated which will cause so much troubles. Better to try my code below</b>.\n",
    "  * However, since these deep learning open sources keep updating and deprecating functions, you will never know whether a previous tutorial works for you at the time when you try. This is one of the reasons I hate deep learning.\n",
    "* To compare with Keras code in Digit Recognition: https://github.com/hanhanwu/Hanhan_Data_Science_Practice/blob/master/AI_Experiments/digital_recognition_Keras.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio as io\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "\n",
    "# Get data from here: https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Train_digits/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# randomly display an image\n",
    "img_name = rng.choice(train.filename)\n",
    "training_image_path = 'Train_digits/Images/train/' + img_name\n",
    "\n",
    "training_img = io.imread(training_image_path, as_gray=True)\n",
    "\n",
    "pylab.imshow(training_img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Image([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just 1 image\n",
    "print(training_img.shape)\n",
    "training_img[0]  # each image has 28x28 pixel square, 784 pixels in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all images as numpy arrays, to make data manipulation easier\n",
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    training_image_path = 'Train_digits/Images/train/' + img_name\n",
    "    training_img = io.imread(training_image_path, as_gray=True)  # !!! as_gray param makes a difference here!!\n",
    "    img = training_img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "train_x /= 255.0\n",
    "train_x = train_x.reshape(-1, 784).astype('float32')  # 784 pixels per image \n",
    "\n",
    "train_y = train.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `as_gray` param in `io.imread()`, it will help you get train_x, train_y have the same length. Otherwise there will be so much troubles in creating batches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 9, 1, ..., 9, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_y.shape)  # 49000 images in total\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34300, 784) (34300,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[4 9 1 ... 4 0 6]\n"
     ]
    }
   ],
   "source": [
    "# create validation set\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(train_x)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pytorch to build the model\n",
    "from torch.autograd import Variable\n",
    "\n",
    "## number of neurons in each layer\n",
    "input_num_units = 28*28  # 784 pixels per image\n",
    "hidden_num_units = 500\n",
    "output_num_units = 10  # 0 - 9, 10 digits\n",
    "\n",
    "## set variables used in NN\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(input_num_units, hidden_num_units),\n",
    "  torch.nn.ReLU(),\n",
    "  torch.nn.Linear(hidden_num_units, output_num_units),\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define optimization algorithm\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess a batch of dataset\n",
    "def preproc(unclean_batch_x):\n",
    "    \"\"\"Convert values to range 0-1\"\"\"\n",
    "    temp_batch = unclean_batch_x / unclean_batch_x.max()\n",
    " \n",
    "    return temp_batch\n",
    "\n",
    "# create a batch\n",
    "def batch_creator(batch_size):\n",
    "    dataset_name = 'train'\n",
    "    dataset_length = eval(dataset_name+'_x').shape[0]\n",
    "  \n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "  \n",
    "    batch_x = eval(dataset_name+'_x')[batch_mask]\n",
    "    batch_x = preproc(batch_x)\n",
    "  \n",
    "    batch_y = eval(dataset_name+'_y')[batch_mask]  # train_x, train_y has the same length\n",
    "  \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.7093)\n",
      "1 tensor(0.6976)\n",
      "2 tensor(0.6666)\n",
      "3 tensor(0.6627)\n",
      "4 tensor(0.6538)\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "total_batch = int(train.shape[0]/batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        # create batch\n",
    "        batch_x, batch_y = batch_creator(batch_size)\n",
    "\n",
    "        # pass that batch for training\n",
    "        x, y = Variable(torch.from_numpy(batch_x)), Variable(torch.from_numpy(batch_y), requires_grad=False)\n",
    "        pred = model(x)\n",
    "\n",
    "        # get loss\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # perform backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += loss.data/total_batch\n",
    "\n",
    "    print(epoch, avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284548104956269"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get training accuracy\n",
    "x, y = Variable(torch.from_numpy(preproc(train_x))), Variable(torch.from_numpy(train_y), requires_grad=False)\n",
    "pred = model(x)\n",
    "\n",
    "final_pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "\n",
    "accuracy_score(train_y, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8196598639455782"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get validation accuracy\n",
    "x, y = Variable(torch.from_numpy(preproc(val_x))), Variable(torch.from_numpy(val_y), requires_grad=False)\n",
    "pred = model(x)\n",
    "final_pred = np.argmax(pred.data.numpy(), axis=1)\n",
    "\n",
    "accuracy_score(val_y, final_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Again, a simple deep learning problem cost me so much time to debug because of the updates in these open sources!\n",
    "  * Simple param makes a difference, in this case, `imread()` from scipy got deprecated, you have to change to `imageio.imread()`, which replaced \"flatten\" with \"as_gray\", without this param, your train_x, train_y will get different length after converting to numpy array, which will cause so much trouble when creating batches later.\n",
    "  * This is why I hate deep learing, software updates, and so much dimentions conversion, difficult to find problems and time consuming to debug.\n",
    "* For this case, comparing with Keras, I think Pytorch is more complex to use, especially when thinking about it cost me so much time to debug when creating batches, while Keras will just do that for you! Not sure why many people are crazy about Pytorch (maybe it's better than Tensorflow...)\n",
    "* When building the model, the neural network structure is easier to understand than keras, since it will show you the order between layers and the activation functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
