{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# Get data from here: https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 410\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABVdJREFUeJzt3TGPTlsbgOHzciIiCtHKdAqFKESnENGJZBL/gJ+gUgid\nRkKjlFDpKSdRSESjFESnoFQIJqKwT+NrvpNZxhn7Hea+rvZ5Z6+VSe5ZxZo9s5im6S+gZ9d2bwDY\nHuKHKPFDlPghSvwQJX6IEj9EiR+ixA9Rfy9zscVi4dcJYWbTNC028zknP0SJH6LED1HihyjxQ5T4\nIUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU\n+CFK/BAlfogSP0SJH6LED1HihyjxQ9Tf272B38Xhw4eH8/Pnzy9pJ/92/fr14XzXrvl+hi8Wi+F8\nmqb//OyrV68O58+fPx/OHzx48J/XxskPWeKHKPFDlPghSvwQJX6IEj9ELbZyT/vTiy0Wy1vsJz17\n9mw4P378+JJ2wv98/fp1OF9bWxvOV1dXf+V2/hjTNI1/OeM7Jz9EiR+ixA9R4oco8UOU+CFK/BDl\nnv+7CxcuDOd37txZ0k7YrPX19eH83LlzG84eP378q7fz23DPDwyJH6LED1HihyjxQ5T4IUr8EOXv\n9n/38OHD4fzUqVNL2smf5UfvzJ88eXLD2YkTJ4Zfu3v37uF83759w/n+/fuH8zonP0SJH6LED1Hi\nhyjxQ5T4IUr8EOWe/7v3798P50+ePFnSTv4sW/m+fPjwYTh3Tz8vJz9EiR+ixA9R4oco8UOU+CFK\n/BAlfogSP0SJH6LED1HihyjxQ5T4Icorvczq9OnTG8727NmzxJ3w/5z8ECV+iBI/RIkfosQPUeKH\nKPFDlHt+tuRH/0b70qVLG862es//7t274fzNmzdbev5O5+SHKPFDlPghSvwQJX6IEj9EiR+i3POz\nJdeuXRvOz549O9vaFy9eHM5fvHgx29o7gZMfosQPUeKHKPFDlPghSvwQJX6Ics/P0N69e4fzo0eP\nzrb2o0ePhvOnT5/OtnaBkx+ixA9R4oco8UOU+CFK/BDlqo+hY8eODeerq6uzrf3y5cvhfH19fba1\nC5z8ECV+iBI/RIkfosQPUeKHKPFDlHv+uB/9m+zLly/PtvaPXtm9cuXKbGvj5Ics8UOU+CFK/BAl\nfogSP0SJH6Lc88dt5/v6N2/eHM4/ffo029o4+SFL/BAlfogSP0SJH6LED1Hih6jFNE3LW2yxWN5i\nbMra2tpwfubMmdnWPnDgwHD+8ePH2dbeyaZpWmzmc05+iBI/RIkfosQPUeKHKPFDlFd6d7iVlZXh\n/NChQ0vaCb8bJz9EiR+ixA9R4oco8UOU+CFK/BDlnn+Hu3v37nB+5MiRWde/ffv2hrPPnz/PujZj\nTn6IEj9EiR+ixA9R4oco8UOU+CHKPf8Od/DgwVmf//r16+H8xo0bG86+ffv2q7fDT3DyQ5T4IUr8\nECV+iBI/RIkfosQPUe75d7h79+4N57du3drS8798+TKcv337dkvPZz5OfogSP0SJH6LED1Hihyjx\nQ5T4Ico9/w736tWrWZ+/srIy6/OZj5MfosQPUeKHKPFDlPghSvwQ5aqPofv37w/nW30lmO3j5Ico\n8UOU+CFK/BAlfogSP0SJH6IW0zQtb7HFYnmLQdQ0TYvNfM7JD1HihyjxQ5T4IUr8ECV+iBI/RC31\nnh/4fTj5IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAl\nfogSP0SJH6LED1Hih6h/AK8unvi48K4jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d9d290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "training_image_path = 'data/Images/train/' + img_name\n",
    "\n",
    "training_img = imread(training_image_path, flatten=True)\n",
    "\n",
    "pylab.imshow(training_img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,   10.,   59.,\n",
       "          59.,   67.,  119.,  156.,  194.,  194.,  156.,  156.,  141.,\n",
       "          14.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,   62.,  185.,  220.,  253.,\n",
       "         254.,  253.,  253.,  253.,  253.,  249.,  233.,  239.,  253.,\n",
       "         185.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,   23.,  229.,  253.,  253.,  253.,\n",
       "         175.,   92.,   78.,   78.,   78.,   60.,    0.,   48.,  245.,\n",
       "         253.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,   62.,   48.,   19.,   19.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,   94.,  253.,\n",
       "         200.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    8.,  205.,  253.,\n",
       "          80.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,   80.,  254.,  229.,\n",
       "          23.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  200.,  253.,  168.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,  214.,  253.,   87.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,   32.,  235.,  253.,   19.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,   59.,  253.,  253.,   19.,\n",
       "           0.,   23.,   52.,    0.,   76.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,   93.,  134.,  141.,  254.,  254.,  254.,\n",
       "         254.,  255.,  254.,  213.,  128.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,  149.,  250.,  253.,  254.,  253.,  247.,  218.,\n",
       "         135.,  113.,   39.,   12.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,   54.,  115.,   78.,  186.,  253.,  107.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,  194.,  234.,    6.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,  194.,  233.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,  255.,  234.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,  254.,  233.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,  186.,  233.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,  141.,  243.,   42.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,   36.,  223.,   18.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.],\n",
       "       [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each image is represented as numpy array\n",
    "\n",
    "training_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store all images as numpy arrays, to make data manipulation easier\n",
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    training_image_path = 'data/Images/train/' + img_name\n",
    "    training_img = imread(training_image_path, flatten=True)\n",
    "    img = training_img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "train_x /= 255.0\n",
    "train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    testing_image_path = 'data/Images/test/' + img_name\n",
    "    testing_img = imread(testing_image_path, flatten=True)\n",
    "    img = testing_img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "test_x = test_x.reshape(-1, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and validation sets, 7:3\n",
    "\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34300    3\n",
       "34301    1\n",
       "34302    6\n",
       "34303    8\n",
       "34304    3\n",
       "34305    8\n",
       "34306    8\n",
       "34307    9\n",
       "34308    3\n",
       "34309    8\n",
       "34310    4\n",
       "34311    6\n",
       "34312    6\n",
       "34313    3\n",
       "34314    6\n",
       "34315    7\n",
       "34316    5\n",
       "34317    3\n",
       "34318    0\n",
       "34319    3\n",
       "34320    9\n",
       "34321    3\n",
       "34322    8\n",
       "34323    8\n",
       "34324    7\n",
       "34325    4\n",
       "34326    3\n",
       "34327    8\n",
       "34328    6\n",
       "34329    5\n",
       "        ..\n",
       "48970    7\n",
       "48971    5\n",
       "48972    0\n",
       "48973    1\n",
       "48974    4\n",
       "48975    1\n",
       "48976    7\n",
       "48977    5\n",
       "48978    6\n",
       "48979    5\n",
       "48980    6\n",
       "48981    3\n",
       "48982    5\n",
       "48983    5\n",
       "48984    9\n",
       "48985    2\n",
       "48986    9\n",
       "48987    0\n",
       "48988    0\n",
       "48989    7\n",
       "48990    0\n",
       "48991    1\n",
       "48992    1\n",
       "48993    6\n",
       "48994    9\n",
       "48995    2\n",
       "48996    4\n",
       "48997    9\n",
       "48998    3\n",
       "48999    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.ix[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50, activation=\"relu\", input_dim=784)`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, activation=\"softmax\", input_dim=50)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "input_num_units = 784\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "  Dense(output_dim=hidden_num_units, input_dim=input_num_units, activation='relu'),\n",
    "  Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile the model with necessary attributes\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/5\n",
      "34300/34300 [==============================] - 1s - loss: 0.5080 - acc: 0.8657 - val_loss: 0.2955 - val_acc: 0.9162\n",
      "Epoch 2/5\n",
      "34300/34300 [==============================] - 1s - loss: 0.2469 - acc: 0.9299 - val_loss: 0.2328 - val_acc: 0.9349\n",
      "Epoch 3/5\n",
      "34300/34300 [==============================] - 1s - loss: 0.1932 - acc: 0.9449 - val_loss: 0.1991 - val_acc: 0.9454\n",
      "Epoch 4/5\n",
      "34300/34300 [==============================] - 1s - loss: 0.1606 - acc: 0.9538 - val_loss: 0.1810 - val_acc: 0.9477\n",
      "Epoch 5/5\n",
      "34300/34300 [==============================] - 1s - loss: 0.1369 - acc: 0.9613 - val_loss: 0.1609 - val_acc: 0.9546\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "\n",
    "trained_model = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19296/21000 [==========================>...] - ETA: 0sPrediction is:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niR9C/Q22VikjiZBQMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae225d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model evaluation\n",
    "\n",
    "pred = model.predict_classes(test_x)\n",
    "\n",
    "img_name = rng.choice(test.filename)\n",
    "testing_image_path = 'data/Images/test/' + img_name\n",
    "testing_img = imread(testing_image_path, flatten=True)\n",
    "\n",
    "test_index = int(img_name.split('.')[0]) - train.shape[0]\n",
    "\n",
    "print \"Prediction is: \", pred[test_index]\n",
    "\n",
    "pylab.imshow(testing_img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50, activation=\"relu\", input_dim=784)`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50, activation=\"relu\", input_dim=50)`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50, activation=\"relu\", input_dim=50)`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50, activation=\"relu\", input_dim=50)`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50, activation=\"relu\", input_dim=50)`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:30: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, activation=\"softmax\", input_dim=50)`\n"
     ]
    }
   ],
   "source": [
    "# Improve the model\n",
    "## Add hidden layers\n",
    "## add Dropout to avoid overfitting\n",
    "## increase epochs to increase training potentials\n",
    "\n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\n",
    "\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "model = Sequential([\n",
    " Dense(output_dim=hidden1_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden4_num_units, input_dim=hidden3_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    " Dense(output_dim=hidden5_num_units, input_dim=hidden4_num_units, activation='relu'),\n",
    " Dropout(0.2),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden5_num_units, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/50\n",
      "34300/34300 [==============================] - 2s - loss: 1.1752 - acc: 0.5934 - val_loss: 0.3836 - val_acc: 0.8929\n",
      "Epoch 2/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.4911 - acc: 0.8594 - val_loss: 0.2781 - val_acc: 0.9224\n",
      "Epoch 3/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.3748 - acc: 0.8993 - val_loss: 0.2298 - val_acc: 0.9364\n",
      "Epoch 4/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.3172 - acc: 0.9155 - val_loss: 0.2131 - val_acc: 0.9420\n",
      "Epoch 5/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.2834 - acc: 0.9243 - val_loss: 0.1953 - val_acc: 0.9471\n",
      "Epoch 6/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.2648 - acc: 0.9296 - val_loss: 0.1901 - val_acc: 0.9488\n",
      "Epoch 7/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.2413 - acc: 0.9371 - val_loss: 0.1849 - val_acc: 0.9504\n",
      "Epoch 8/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.2327 - acc: 0.9383 - val_loss: 0.1664 - val_acc: 0.9543\n",
      "Epoch 9/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.2172 - acc: 0.9426 - val_loss: 0.1712 - val_acc: 0.9537\n",
      "Epoch 10/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.2026 - acc: 0.9466 - val_loss: 0.1734 - val_acc: 0.9544\n",
      "Epoch 11/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1983 - acc: 0.9481 - val_loss: 0.1543 - val_acc: 0.9576\n",
      "Epoch 12/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1907 - acc: 0.9516 - val_loss: 0.1627 - val_acc: 0.9564\n",
      "Epoch 13/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1798 - acc: 0.9522 - val_loss: 0.1694 - val_acc: 0.9548\n",
      "Epoch 14/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1809 - acc: 0.9526 - val_loss: 0.1548 - val_acc: 0.9582\n",
      "Epoch 15/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1714 - acc: 0.9551 - val_loss: 0.1620 - val_acc: 0.9575\n",
      "Epoch 16/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1705 - acc: 0.9543 - val_loss: 0.1528 - val_acc: 0.9578\n",
      "Epoch 17/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1565 - acc: 0.9584 - val_loss: 0.1563 - val_acc: 0.9587\n",
      "Epoch 18/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1554 - acc: 0.9595 - val_loss: 0.1562 - val_acc: 0.9595\n",
      "Epoch 19/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1586 - acc: 0.9585 - val_loss: 0.1518 - val_acc: 0.9595\n",
      "Epoch 20/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1552 - acc: 0.9578 - val_loss: 0.1516 - val_acc: 0.9591\n",
      "Epoch 21/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1535 - acc: 0.9600 - val_loss: 0.1505 - val_acc: 0.9607\n",
      "Epoch 22/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1451 - acc: 0.9619 - val_loss: 0.1513 - val_acc: 0.9620\n",
      "Epoch 23/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1453 - acc: 0.9608 - val_loss: 0.1465 - val_acc: 0.9624\n",
      "Epoch 24/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1360 - acc: 0.9633 - val_loss: 0.1464 - val_acc: 0.9610\n",
      "Epoch 25/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1308 - acc: 0.9651 - val_loss: 0.1384 - val_acc: 0.9636\n",
      "Epoch 26/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1362 - acc: 0.9641 - val_loss: 0.1544 - val_acc: 0.9610\n",
      "Epoch 27/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1329 - acc: 0.9644 - val_loss: 0.1464 - val_acc: 0.9629\n",
      "Epoch 28/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1256 - acc: 0.9671 - val_loss: 0.1495 - val_acc: 0.9627\n",
      "Epoch 29/50\n",
      "34300/34300 [==============================] - 1s - loss: 0.1275 - acc: 0.9666 - val_loss: 0.1477 - val_acc: 0.9622\n",
      "Epoch 30/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1304 - acc: 0.9644 - val_loss: 0.1435 - val_acc: 0.9635\n",
      "Epoch 31/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1254 - acc: 0.9671 - val_loss: 0.1431 - val_acc: 0.9629\n",
      "Epoch 32/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1255 - acc: 0.9665 - val_loss: 0.1437 - val_acc: 0.9631\n",
      "Epoch 33/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1193 - acc: 0.9674 - val_loss: 0.1463 - val_acc: 0.9642\n",
      "Epoch 34/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1202 - acc: 0.9682 - val_loss: 0.1442 - val_acc: 0.9646\n",
      "Epoch 35/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1217 - acc: 0.9678 - val_loss: 0.1515 - val_acc: 0.9610\n",
      "Epoch 36/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1185 - acc: 0.9683 - val_loss: 0.1464 - val_acc: 0.9631\n",
      "Epoch 37/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1187 - acc: 0.9679 - val_loss: 0.1473 - val_acc: 0.9630\n",
      "Epoch 38/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1146 - acc: 0.9693 - val_loss: 0.1501 - val_acc: 0.9645\n",
      "Epoch 39/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1112 - acc: 0.9701 - val_loss: 0.1442 - val_acc: 0.9641\n",
      "Epoch 40/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1110 - acc: 0.9697 - val_loss: 0.1424 - val_acc: 0.9656\n",
      "Epoch 41/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1143 - acc: 0.9685 - val_loss: 0.1429 - val_acc: 0.9626\n",
      "Epoch 42/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1133 - acc: 0.9695 - val_loss: 0.1444 - val_acc: 0.9635\n",
      "Epoch 43/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1049 - acc: 0.9716 - val_loss: 0.1462 - val_acc: 0.9635\n",
      "Epoch 44/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1062 - acc: 0.9717 - val_loss: 0.1443 - val_acc: 0.9656\n",
      "Epoch 45/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1032 - acc: 0.9727 - val_loss: 0.1418 - val_acc: 0.9645\n",
      "Epoch 46/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1038 - acc: 0.9719 - val_loss: 0.1504 - val_acc: 0.9638\n",
      "Epoch 47/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1049 - acc: 0.9718 - val_loss: 0.1546 - val_acc: 0.9623\n",
      "Epoch 48/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1075 - acc: 0.9710 - val_loss: 0.1453 - val_acc: 0.9643\n",
      "Epoch 49/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1080 - acc: 0.9707 - val_loss: 0.1506 - val_acc: 0.9631\n",
      "Epoch 50/50\n",
      "34300/34300 [==============================] - 2s - loss: 0.1047 - acc: 0.9717 - val_loss: 0.1471 - val_acc: 0.9652\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_5d_with_drop_more_epochs = model.fit(train_x, train_y, nb_epoch=epochs, \n",
    "                                                   batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/7\n",
      "34300/34300 [==============================] - 35s - loss: 0.4930 - acc: 0.8502 - val_loss: 0.1768 - val_acc: 0.9463\n",
      "Epoch 2/7\n",
      "34300/34300 [==============================] - 34s - loss: 0.1229 - acc: 0.9629 - val_loss: 0.1033 - val_acc: 0.9680\n",
      "Epoch 3/7\n",
      "34300/34300 [==============================] - 30s - loss: 0.0840 - acc: 0.9745 - val_loss: 0.0839 - val_acc: 0.9746\n",
      "Epoch 4/7\n",
      "34300/34300 [==============================] - 30s - loss: 0.0664 - acc: 0.9789 - val_loss: 0.0732 - val_acc: 0.9781\n",
      "Epoch 5/7\n",
      "34300/34300 [==============================] - 32s - loss: 0.0544 - acc: 0.9827 - val_loss: 0.0626 - val_acc: 0.9814\n",
      "Epoch 6/7\n",
      "34300/34300 [==============================] - 32s - loss: 0.0454 - acc: 0.9852 - val_loss: 0.0659 - val_acc: 0.9808\n",
      "Epoch 7/7\n",
      "34300/34300 [==============================] - 32s - loss: 0.0389 - acc: 0.9871 - val_loss: 0.0904 - val_acc: 0.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (5, 5), activation=\"relu\")`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (5, 5), activation=\"relu\")`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(25, (4, 4), activation=\"relu\")`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:37: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50, activation=\"relu\")`\n",
      "/Library/Python/2.7/site-packages/ipykernel-4.2.1-py2.7.egg/ipykernel/__main__.py:39: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10, activation=\"softmax\", input_dim=50)`\n"
     ]
    }
   ],
   "source": [
    "# The above is using NN type 1 - MLP (multi-layer perceptrons)\n",
    "# NN type 2 - CNN\n",
    "\n",
    "# reshape data\n",
    "## each given image here is 28*28\n",
    "train_x_temp = train_x.reshape(-1, 28, 28, 1)\n",
    "val_x_temp = val_x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# define vars\n",
    "input_shape = (784,)\n",
    "input_reshape = (28, 28, 1)\n",
    "\n",
    "conv_num_filters = 5\n",
    "conv_filter_size = 5\n",
    "\n",
    "pool_size = (2, 2)\n",
    "\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 7\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    " InputLayer(input_shape=input_reshape),\n",
    "\n",
    " Convolution2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    " Convolution2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    " Convolution2D(25, 4, 4, activation='relu'),\n",
    "\n",
    " Flatten(),\n",
    "\n",
    " Dense(output_dim=hidden_num_units, activation='relu'),\n",
    "\n",
    " Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_conv = model.fit(train_x_temp, train_y, nb_epoch=epochs, batch_size=batch_size, \n",
    "                               validation_data=(val_x_temp, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TO-DO: predict results from CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (Virtual_Env)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
