{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get data from here: https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: 16\n"
     ]
    }
   ],
   "source": [
    "## Very simple sample process of using Tensorflow\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# build computational graph\n",
    "a = tf.placeholder(tf.int16)\n",
    "b = tf.placeholder(tf.int16)\n",
    "\n",
    "addition = tf.add(a, b)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# create session and run the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print \"Addition: %i\" % sess.run(addition, feed_dict={a: 7, b: 9})\n",
    "\n",
    "# close session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic Steps to build NN\n",
    "\n",
    "'''\n",
    "Define Neural Network architecture\n",
    "Transfer data to your model\n",
    "Divide Data into batches. The batches are first preprocessed, augmented and then fed into Neural Network for training\n",
    "The model then gets trained incrementally\n",
    "Display the accuracy for a specific number of timesteps\n",
    "After training save the model for future use\n",
    "Test the model on a new data and check how it performs\n",
    "'''\n",
    "\n",
    "# Below is digit recignition\n",
    "## Using eed forward multilayer perceptron here, but you have freedom to choose which architecture to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 410\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niR9CiR9C/QC5SOw9zbV0vwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ab33790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join('data/Images/train/', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store all our images as numpy arrays, for easier data manipulation\n",
    "\n",
    "temp = []\n",
    "for img_name in train.filename:\n",
    "    image_path = os.path.join('data/Images/train/', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "    image_path = os.path.join('data/Images/test/', img_name)\n",
    "    img = imread(image_path, flatten=True)\n",
    "    img = img.astype('float32')\n",
    "    temp.append(img)\n",
    "    \n",
    "test_x = np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training and validation data into 7:3\n",
    "\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train.label.values[:split_size], train.label.values[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Different from Keras, you need to define these functions on your own\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes=10):    # 0 to 9, 10 classes\n",
    "    \"\"\"Convert class labels from scalars to one-hot vectors\"\"\"\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    \n",
    "    return labels_one_hot\n",
    "\n",
    "\n",
    "def preproc(unclean_batch_x):\n",
    "    \"\"\"Convert values to range 0-1\"\"\"\n",
    "    temp_batch = unclean_batch_x / unclean_batch_x.max()\n",
    "    \n",
    "    return temp_batch\n",
    "\n",
    "\n",
    "def batch_creator(batch_size, dataset_length, dataset_name):\n",
    "    \"\"\"Create batch with random samples and return appropriate format\"\"\"\n",
    "    batch_mask = rng.choice(dataset_length, batch_size)\n",
    "    \n",
    "    batch_x = eval(dataset_name + '_x')[[batch_mask]].reshape(-1, input_num_units)\n",
    "    batch_x = preproc(batch_x)\n",
    "    \n",
    "    if dataset_name == 'train':\n",
    "        batch_y = eval(dataset_name).ix[batch_mask, 'label'].values\n",
    "        batch_y = dense_to_one_hot(batch_y)\n",
    "        \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set Variables\n",
    "\n",
    "input_num_units = 28*28    # size of original images\n",
    "hidden_num_units = 410    # number of neurnos in each layer\n",
    "output_num_units = 10\n",
    "\n",
    "# define placeholders\n",
    "x = tf.placeholder(tf.float32, [None, input_num_units])\n",
    "y = tf.placeholder(tf.float32, [None, output_num_units])\n",
    "\n",
    "# set remaining variables\n",
    "epochs = 7\n",
    "batch_size = 179\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([input_num_units, hidden_num_units], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([hidden_num_units, output_num_units], seed=seed))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([hidden_num_units], seed=seed)),\n",
    "    'output': tf.Variable(tf.random_normal([output_num_units], seed=seed))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build neural networks computational graph\n",
    "\n",
    "hidden_layer = tf.add(tf.matmul(x, weights['hidden']), biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "\n",
    "output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']\n",
    "\n",
    "## cost of the graph\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits = output_layer))\n",
    "\n",
    "## Using Adam optimizer here\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost = 8.93436\n",
      "Epoch: 2 cost = 1.65344\n",
      "Epoch: 3 cost = 0.84183\n",
      "Epoch: 4 cost = 0.49784\n",
      "Epoch: 5 cost = 0.36253\n",
      "Epoch: 6 cost = 0.24408\n",
      "Epoch: 7 cost = 0.21394\n",
      "\n",
      "Training complete!\n",
      "Validation Accuracy: 0.955782\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    ### for each epoch, do:\n",
    "    ###   for each batch, do:\n",
    "    ###     create pre-processed batch\n",
    "    ###     run optimizer by feeding batch\n",
    "    ###     find cost and reiterate to minimize\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(train.shape[0]/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = batch_creator(batch_size, train_x.shape[0], 'train')\n",
    "            _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch_y})\n",
    "            \n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print \"Epoch:\", (epoch+1), \"cost =\", \"{:.5f}\".format(avg_cost)\n",
    "    \n",
    "    print \"\\nTraining complete!\"\n",
    "    \n",
    "    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp, \"float\"))\n",
    "    print \"Validation Accuracy:\", accuracy.eval({x: val_x.reshape(-1, input_num_units), y: dense_to_one_hot(val_y)})\n",
    "    \n",
    "    predict = tf.argmax(output_layer, 1)\n",
    "    pred = predict.eval({x: test_x.reshape(-1, input_num_units)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEOpvvxxA8HpDgNgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b0cc4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(test.filename)\n",
    "filepath = os.path.join('data/Images/test/', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "test_index = int(img_name.split('.')[0]) - 49000\n",
    "\n",
    "print \"Prediction is: \", pred[test_index]\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (Virtual_Env)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
